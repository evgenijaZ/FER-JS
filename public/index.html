<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Emotion recognition</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
</head>
<body style="background-color:rgba(0, 0, 0, 0.7); color: #C4CFE5">
<div class="cover-container d-flex w-100 h-100 p-3 mx-auto flex-column">

    <main role="main" class="container">
        <div class="starter-template" style="text-align: center">
            <h1>Emotion recognition method</h1>
            <p class="lead">Based on local binary patterns method<br>and bidirectional LSTM model.</p>
        </div>
        <div class="d-flex justify-content-center">
            <div class="control">
                <button class="btn btn-lg  btn-secondary" id="startAndStop" disabled>Start</button>
            </div>
        </div>
        <div class="d-flex flex-row">
            <video class="m-2" id="videoInput"></video>
            <canvas class="m-2 align-self-center" id="canvasOutput" width=48 height=144></canvas>
            <div class="d-flex flex-column m-2 align-self-center">
                <h4 id="emotionHeader" hidden="hidden">Emotion</h4>
                <div style="text-align: left" id="emotionOutput"></div>
            </div>
        </div>
        <p class="err" id="errorMessage"></p>
    </main>
</div>
<script src="https://webrtc.github.io/adapter/adapter-5.0.4.js" type="text/javascript"></script>
<script src="js/videoProcessor.js" type="text/javascript"></script>
<script type="text/javascript">
    let utils = new VideoProcessor('errorMessage');
    let streaming = false;
    let videoInput = document.getElementById('videoInput');
    let startAndStop = document.getElementById('startAndStop');
    let canvasOutput = document.getElementById('canvasOutput');
    let canvasContext = canvasOutput.getContext('2d');
    let emotionsOutput = document.getElementById('emotionOutput');
    let emotionHeader = document.getElementById('emotionHeader');

    startAndStop.addEventListener('click', () => {
        if (!streaming) {
            utils.clearError();
            utils.startCamera('vga', onVideoStarted, 'videoInput');
        } else {
            utils.stopCamera();
            onVideoStopped();
        }
    });

    function onVideoStarted() {
        streaming = true;
        startAndStop.innerText = 'Stop';
        videoInput.width = videoInput.videoWidth;
        videoInput.height = videoInput.videoHeight;
        emotionHeader.hidden = false;
        utils.processVideo('videoInput', 'canvasOutput', 'lbpcascade_frontalface_improved.xml', 'emotionOutput');
    }

    function onVideoStopped() {
        streaming = false;
        canvasContext.clearRect(0, 0, canvasOutput.width, canvasOutput.height);
        startAndStop.innerText = 'Start';
        emotionHeader.hidden = true;
    }

    utils.loadOpenCv(() => {
        let faceCascadeFile = 'lbpcascade_frontalface_improved.xml';
        utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {
            startAndStop.removeAttribute('disabled');
        });
    });
</script>
</body>
</html>
